import os
import tensorflow as tf
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import json
from sklearn.metrics import classification_report, confusion_matrix

# Data Preprocessing with Path Validation
train = r"C:\Users\subar\Downloads\plants\split_ttv_dataset_type_of_plants\Train_Set_Folder"
validation = r"C:\Users\subar\Downloads\plants\split_ttv_dataset_type_of_plants\Validation_Set_Folder"

print("Checking dataset paths and structure...")
if not os.path.exists(train) or len(os.listdir(train)) == 0:
    raise ValueError(f"Training directory is empty or not found: {train}")
if not os.path.exists(validation) or len(os.listdir(validation)) == 0:
    raise ValueError(f"Validation directory is empty or not found: {validation}")

training_set = tf.keras.utils.image_dataset_from_directory(
    train,
    labels="inferred",
    label_mode="categorical",
    batch_size=32,
    image_size=(128, 128),
    shuffle=True
)

validation_set = tf.keras.utils.image_dataset_from_directory(
    validation,
    labels="inferred",
    label_mode="categorical",
    batch_size=32,
    image_size=(128, 128),
    shuffle=True
)

# Check shapes of images and labels
for x, y in training_set:
    print(x.shape)
    print(y.shape)
    break

# Model Building
from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout
from tensorflow.keras.models import Sequential

model = Sequential()

# Convolutional Layers
model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=[128, 128, 3]))
model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))
model.add(MaxPool2D(pool_size=2, strides=2, padding='valid'))
model.add(Dropout(0.2))

model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))
model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))
model.add(MaxPool2D(pool_size=2, strides=2, padding='valid'))
model.add(Dropout(0.3))

model.add(Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))
model.add(Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))
model.add(MaxPool2D(pool_size=2, strides=2, padding='valid'))
model.add(Dropout(0.4))

# Flattening and Fully Connected Layers
model.add(Flatten())
model.add(Dense(units=512, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(units=len(training_set.class_names), activation='softmax'))  # Number of classes = len(class_names)

# Compiling the Model
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
              loss='categorical_crossentropy', metrics=['accuracy'])

# Model Summary
model.summary()

# Training the Model
training_history = model.fit(x=training_set, validation_data=validation_set, epochs=15)

# Evaluate Model
train_loss, train_acc = model.evaluate(training_set)
val_loss, val_acc = model.evaluate(validation_set)
print(f"Training Loss: {train_loss}, Training Accuracy: {train_acc}")
print(f"Validation Loss: {val_loss}, Validation Accuracy: {val_acc}")

# Save Model
model.save("plant_disease_detection_model.keras")

# Save Training History
with open("training_history.json", "w") as f:
    json.dump(training_history.history, f)

# Accuracy Visualization
epochs = range(1, 16)
plt.figure(figsize=(10, 5))
plt.plot(epochs, training_history.history['accuracy'], color='red', label='Training Accuracy')
plt.plot(epochs, training_history.history['val_accuracy'], color='blue', label='Validation Accuracy')
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.title("Training and Validation Accuracy")
plt.show()

# Evaluate with Confusion Matrix
test_set = tf.keras.utils.image_dataset_from_directory(
    validation,
    labels="inferred",
    label_mode="categorical",
    batch_size=32,
    image_size=(128, 128),
    shuffle=False
)

y_pred = model.predict(test_set)
y_pred_classes = tf.argmax(y_pred, axis=1)
y_true = tf.concat([y for x, y in test_set], axis=0)
y_true_classes = tf.argmax(y_true, axis=1)

class_names = test_set.class_names
print(classification_report(y_true_classes, y_pred_classes, target_names=class_names))

# Confusion Matrix
cm = confusion_matrix(y_true_classes, y_pred_classes)
plt.figure(figsize=(12, 10))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.title('Confusion Matrix')
plt.show()


